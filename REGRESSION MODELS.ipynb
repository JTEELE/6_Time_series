{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERAL LR MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Simulated data\n",
    "np.random.seed(0)\n",
    "num_samples = 1000\n",
    "num_features = 3\n",
    "X = np.random.rand(num_samples, num_features)  # Features: bedrooms, square footage, neighborhood income\n",
    "true_coefficients = np.array([30000, 150, 1000])  # True coefficients for features\n",
    "noise = np.random.normal(0, 2000, num_samples)  # Adding some noise\n",
    "y = X.dot(true_coefficients) + noise  # Simulated house prices\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Creating and training the Linear Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Predicting house prices\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculating mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Simulated data\n",
    "np.random.seed(0)\n",
    "num_samples = 50\n",
    "temperature = np.random.uniform(10, 40, num_samples)  # Simulated outdoor temperature\n",
    "sales = 200 + 5 * temperature - 0.2 * temperature**2 + np.random.normal(0, 50, num_samples)  # Simulated sales\n",
    "# Reshape the data\n",
    "temperature = temperature.reshape(-1, 1)\n",
    "sales = sales.reshape(-1, 1)\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(temperature, sales, test_size=0.2, random_state=42)\n",
    "# Creating polynomial features (quadratic)\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "# Creating and training the Polynomial Regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "# Predicting ice cream sales\n",
    "y_pred = model.predict(X_test_poly)\n",
    "# Calculating mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "# Plotting the results\n",
    "plt.scatter(temperature, sales, color='blue', label='Actual Sales')\n",
    "plt.plot(temperature, model.predict(poly.transform(temperature)), color='red', label='Predicted Sales')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Sales')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Simulated data\n",
    "np.random.seed(0)\n",
    "num_samples = 100\n",
    "earnings = np.random.uniform(1, 10, num_samples)  # Simulated earnings indicator\n",
    "dividends = np.random.uniform(0.1, 1, num_samples)  # Simulated dividends indicator\n",
    "volatility = np.random.uniform(0.05, 0.2, num_samples)  # Simulated volatility indicator\n",
    "stock_price = 50 + 10 * earnings - 5 * dividends + 20 * volatility + np.random.normal(0, 15, num_samples)  # Simulated stock price\n",
    "# Combine indicators into a feature matrix\n",
    "X = np.column_stack((earnings, dividends, volatility))\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, stock_price, test_size=0.2, random_state=42)\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "# Creating and training the Support Vector Regression model\n",
    "model = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Predicting stock prices\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "# Calculating mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "# Plotting the results\n",
    "plt.scatter(y_test, y_pred, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')\n",
    "plt.xlabel('Actual Stock Price')\n",
    "plt.ylabel('Predicted Stock Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Simulated data\n",
    "np.random.seed(0)\n",
    "num_samples = 100\n",
    "occupants = np.random.randint(1, 10, num_samples)  # Simulated number of occupants\n",
    "temperature = np.random.uniform(10, 30, num_samples)  # Simulated outdoor temperature\n",
    "time_of_day = np.random.choice(['morning', 'afternoon', 'evening'], num_samples)  # Simulated time of day\n",
    "energy_consumption = 100 + 5 * occupants + 3 * temperature + np.random.normal(0, 20, num_samples)  # Simulated energy consumption\n",
    "# Encode categorical feature\n",
    "time_of_day_encoded = np.array([0 if t == 'morning' else 1 if t == 'afternoon' else 2 for t in time_of_day]).reshape(-1, 1)\n",
    "# Combine features into a feature matrix\n",
    "X = np.column_stack((occupants, temperature, time_of_day_encoded))\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, energy_consumption, test_size=0.2, random_state=42)\n",
    "# Creating and training the Decision Tree Regression model\n",
    "model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# Predicting energy consumption\n",
    "y_pred = model.predict(X_test)\n",
    "# Calculating mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "# Visualizing the Decision Tree\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(model, feature_names=['Occupants', 'Temperature', 'TimeOfDay'], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Simulated data\n",
    "np.random.seed(0)\n",
    "num_samples = 1000\n",
    "contract_type = np.random.choice(['Month-to-Month', 'One Year', 'Two Year'], num_samples)  # Simulated contract type\n",
    "monthly_charges = np.random.uniform(20, 100, num_samples)  # Simulated monthly charges\n",
    "customer_satisfaction = np.random.randint(1, 6, num_samples)  # Simulated customer satisfaction scores\n",
    "churn_probability = 0.3 * (customer_satisfaction - 3) + 0.2 * (contract_type == 'Month-to-Month') + np.random.normal(0, 0.2, num_samples)  # Simulated churn probability\n",
    "# Encode categorical feature\n",
    "contract_type_encoded = np.array([0 if c == 'Month-to-Month' else 1 if c == 'One Year' else 2 for c in contract_type]).reshape(-1, 1)\n",
    "# Combine features into a feature matrix\n",
    "X = np.column_stack((contract_type_encoded, monthly_charges, customer_satisfaction))\n",
    "# Generate churn labels based on churn probability\n",
    "y = (churn_probability > 0.5).astype(int)\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Creating and training the Random Forest Regression model\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "# Predicting churn probabilities\n",
    "y_pred = model.predict(X_test)\n",
    "# Converting probabilities to binary churn predictions\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "# Calculating accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
